<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TigreGotico Blog</title>
    <link>https://tigregotico.github.io</link>
    <atom:link href="https://tigregotico.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <description>Insights, tutorials, and thoughts on modern web development, technology trends, and best practices.</description>
    <language>en-us</language>
    <copyright>Copyright ¬© 2025 TigreGotico. All rights reserved.</copyright>
    <lastBuildDate>Fri, 07 Nov 2025 19:00:27 GMT</lastBuildDate>
    <pubDate>Mon, 06 Oct 2025 00:00:00 GMT</pubDate>

    <item>
      <title>Introducing phoonnx: The Next Generation of Open Voice for OpenVoiceOS</title>
      <link>https://tigregotico.github.io/blog/2025-10-06-phoonnx</link>
      <guid isPermaLink="true">https://tigregotico.github.io/blog/2025-10-06-phoonnx</guid>
      <pubDate>Mon, 06 Oct 2025 00:00:00 GMT</pubDate>
      <author>Unknown</author>
      <description>Today marks a significant step forward in the OpenVoiceOS journey with the official integration and adoption of phoonnx as our primary Text-to-Speech (TTS) engine.</description>
      <content:encoded><![CDATA[
Introducing phoonnx: The Next Generation of Open Voice for OpenVoiceOS

Today marks a significant step forward in the OpenVoiceOS journey with the official adoption of phoonnx as our primary Text-to-Speech (TTS) framework. 

This new generation of voices is not just about quality; it's about consistency, efficiency, and fulfilling our mission for truly open, offline-ready voice assistants across the globe.

New Language: Introducing Basque!

Building on our previous work on Making Synthetic Voices From Scratch and our successful Arabic TTS Collaboration, we are excited to announce a new milestone in our language support: the addition of new voices for Basque (eu-ES)!

This includes both the male voice (Miro) and female voice (Dii), furthering our mission to support even low-resource languages that lack open, high-quality TTS options.

Previously only a robotic female voice was available, via the AhoTTS plugin made in collaboration with ILENIA.

Hear the results: Examples of the new Basque Open-Source Voices.

<audio controls>
  <source src="/assets/blog/phoonnx/miroeu-ES.wav" type="audio/wav">
  Your browser does not support the audio element.
</audio>

<audio controls>
  <source src="/assets/blog/phoonnx/diieu-ES.wav" type="audio/wav">
  Your browser does not support the audio element.
</audio>

A Unified Voice for a Global Brand

As OpenVoiceOS expands to more languages and more devices, a crucial need has emerged: a cohesive brand identity conveyed through voice. 
We need a core set of voices, a standard male and female persona, that sounds the same, professional, and recognizable no matter where you are in the world or which language you are speaking.

This consistency is vital. Imagine installing OpenVoiceOS in Lisbon, Berlin, or Seattle, the voice should be instantly familiar. 
This is the power of a unified voice, creating a seamless and trustworthy user experience globally.

We are proud to share that TigreGotico has been instrumental in making this vision a reality. 
They are not only developing the core phoonnx engine but are also actively contributing to open datasets and training the default, multi-lingual OVOS voices. 
This internal collaboration accelerates development and ensures our voices are aligned with the open-source spirit of our platform.

The phoonnx Advantage: A Flexible TTS Ecosystem

phoonnx is more than just an inference tool; it is a complete training and inference framework built on the robust VITS architecture. 
This dual capability allows us to rapidly prototype, train, and deploy high-quality voices.

A key to this flexibility is the ability to support diverse phonemizers. 
A phonemizer (or G2P - Grapheme-to-Phoneme model) converts written text into the sequence of sound units (phonemes) the TTS model speaks. 
Different languages may require different, specialized phonemizers for accurate speech.

   eSpeak Compatibility: A core feature is that phoonnx models are fully compatible with the popular Piper TTS engine's runtime, provided they were trained using the widely available eSpeak phonemizer. This ensures easy deployment within the existing OVOS ecosystem and third party projects like Home Assistant.
   Custom Phonemizer Support: The framework is not limited to eSpeak. For example, we are excited to note that the high-quality Galician models developed by Proxecto N√≥s using the Cotovia phonemizer are fully compatible and can be used with the phoonnx pipeline.

This flexibility allows us to integrate and benefit from the work of other open-source projects. In fact, for inference, phoonnx can successfully use models originally trained by other projects, including Coqui, Mimic3, and Piper, solidifying its role as a universal TTS deployment tool.

Teasing the Future: Next-Gen G2P Models

Looking ahead, we are constantly working to improve G2P accuracy, especially for low-resource languages. We are currently developing and testing next-generation G2P models based on the powerful ByT5 architecture. These transformer-based models promise to deliver more accurate and robust phonemization across a wider range of languages.

You can follow their development here: G2P Models Collection.

In the near future a dedicated OVOS TTS plugin will be created for phoonnx and made the default for OpenVoiceOS, replacing the previous plugins: ovos-tts-plugin-piper and ovos-tts-plugin-nos. 

In the meantime you can try the new voices via the existing plugin ovos-tts-plugin-piper

All you need to do is pass the model urls under mycroft.conf

Progress Report: Available Languages

The collective work of the OpenVoiceOS and TigreGotico teams has resulted in a rapidly expanding library of open-source TTS models.

Currently Supported Languages:

 Arabic
 Basque
 Dutch
 English (US/GB)
 French
 German
 Italian
 Portuguese (Brazil/Portugal)
Spanish

Get Involved and Find the Models

We invite the community to explore and utilize these new resources. Your feedback is crucial to improving voice quality and expanding language coverage.

| Resource                 | Description                                                             | Link                                                                                                             |
|:-------------------------|:------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|
| Phoonnx Models       | The new phoonnx-trained TTS models in ONNX format.                      | phoonnx-tts-models |
| Piper/Phoonnx Voices | The full collection of OpenVoiceOS voices compatible with Piper.             | pipertts-voices       |
| Open Datasets        | Datasets used for training these voices, furthering open-data research. | tts-datasets             |

Help Us Build Voice for Everyone

OpenVoiceOS is more than software, it‚Äôs a mission. If you believe voice assistants should be open, inclusive, and user-controlled, here‚Äôs how you can help:
üí∏ Donate: Help us fund development, infrastructure, and legal protection.
üì£ Contribute Open Data: Share voice samples and transcriptions under open licenses.
üåç Translate: Help make OVOS accessible in every language.

We're not building this for profit. We're building it for people. With your support, we can keep voice tech transparent, private, and community-owned.

üëâ Support the project here

---
Read more: <a href="https://tigregotico.github.io/blog/2025-10-06-phoonnx">View full article</a>
]]></content:encoded>
    </item>

    <item>
      <title>OpenVoiceOS and Home Assistant: A Voice Automation Dream Team</title>
      <link>https://tigregotico.github.io/blog/2025-09-17-ovos_ha_dream_team</link>
      <guid isPermaLink="true">https://tigregotico.github.io/blog/2025-09-17-ovos_ha_dream_team</guid>
      <pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate>
      <author>Unknown</author>
      <description>In the world of open-source smart homes, some things just click. When you let Home Assistant handle the automation and let OVOS (Open Voice OS) handle the voice, you get a powerful partnership where each project shines. It‚Äôs a perfect synergy</description>
      <content:encoded><![CDATA[
OpenVoiceOS and Home Assistant: A Voice Automation Dream Team

In the world of open-source smart homes, some things just click. When you let Home Assistant handle the automation and let OVOS (Open Voice OS) handle the voice, you get a powerful partnership where each project shines. It‚Äôs a perfect synergy: one is the undisputed champion of home automation, and the other is a flexible, private powerhouse for voice interaction.

Home Assistant excels at orchestrating your devices and routines, while OVOS provides unparalleled flexibility and privacy in voice interactions. Together, they create a system that's not only robust but also truly yours.

Let's explore how you can bring these two together to create a truly magical smart home experience.

Give Home Assistant an OVOS-Powered Voice

The most direct way to get started is to enhance Home Assistant's built-in voice capabilities with the specialized tools from the OVOS ecosystem. Our main goal is to make OVOS's powerful tools accessible to as many people as possible. 

To achieve this, we've developed dedicated Wyoming integrations that act as bridges, allowing any OVOS Text-to-Speech (TTS), Speech-to-Text (STT), or Wakeword plugin to be exposed to Home Assistant. 

This means you're not limited to a few options; you gain immediate access to the entire rich ecosystem of OVOS voice plugins, bringing a vast array of languages, voices, and recognition models directly into your Home Assistant setup.

 Wyoming OVOS STT: Convert spoken commands into text for Home Assistant to understand.
 Wyoming OVOS TTS: Enable Home Assistant to speak responses using OVOS's diverse voice options.
 Wyoming OVOS Wakeword: Integrate custom wakewords, allowing your Home Assistant setup to respond only when it hears your chosen trigger phrase.

The OVOS Wyoming Docker project makes getting these services up and running a breeze.

Plugin Highlights: Multi-language TTS powered by ILENIA

For us, accessibility is key. That includes language accessibility. We're proud that this integration allows us to bring high-quality, publicly funded voices from projects like ILENIA to a wider audience. Now, Home Assistant users can easily access fantastic, natural-sounding voices for languages like Catalan and Galician.

 Matxa TTS for Catalan: The ovos-tts-plugin-matxa-multispeaker-cat provides multi-speaker text-to-speech capabilities for the Catalan language.
 NosTTS for Galician: The ovos-tts-plugin-nos offers robust text-to-speech in Galician.

It‚Äôs a great example of how open collaboration benefits everyone.

!ILENIA logo

Setting up Wyoming Services in Home Assistant:

When configuring Wyoming services in Home Assistant, you'll typically refer to the official Home Assistant documentation. This process usually involves simply entering the IP address of your Docker container (or the host running your OVOS Wyoming services) into the Home Assistant web interface.

!wyoming setup in Home Assistant

!wyoming entities in Home Assistant

Let OVOS Be the Brains of the Conversation

Want to take it a step further? You can set up OVOS as a full-fledged conversational agent for Home Assistant using the Ollama integration.

!ollama setup in Home Assistant

In this setup, Home Assistant passes the user's text to the ovos-persona-server. OVOS then figures out what you want and tells Home Assistant what to answer. It‚Äôs like hiring a brilliant conversationalist to augment your smart home interactions.

Here‚Äôs the cool part: because ovos-persona-server uses Ollama-compatible endpoints, you can connect it to any app that supports the Ollama or OpenAI APIs. The possibilities are huge!

!chat with OVOS in Home Assistant

OVOS with the Voice Pe

Everyone is talking about Home Assistant Voice Preview Edition, a dedicated hardware device for voice control. If you own one, you can now easily integrate it with everything discussed so far.

!Configuring Home Assistant Voice Preview Edition

Welcome Your OVOS Devices into Home Assistant with HiveMind

If you have dedicated OVOS devices, the HiveMind HomeAssistant project is where the real magic happens. This integration makes your OVOS devices show up as native entities in Home Assistant, giving you a beautiful, unified control panel.

Setting up HiveMind Integration:

To integrate your OVOS devices via HiveMind, you'll typically add the HiveMind integration in Home Assistant. This involves providing connection details such as a name for the integration, an accesskey, password, siteid, host (IP address or hostname of your HiveMind server), and the port (defaulting to 5678). You may also have options to allowselfsigned certificates or enable legacyaudio depending on your setup.

!HiveMind setup in Home Assistant

Exposed Controls for OVOS Devices:

Once integrated, HiveMind exposes a comprehensive set of controls for your OVOS devices directly within Home Assistant. This allows you to manage various aspects of your OVOS device from the Home Assistant UI, including:

   Changing the Listening Mode (e.g., wakeword, always listening)
   Microphone Mute toggle
   OCP Player status and controls
   Actions like Reboot Device, Restart OVOS, and Shutdown Device
   Toggling Sleep Mode and SSH Service
   Manually Start Listening or Stop listening
   Controlling volume level

!HiveMind entities in Home Assistant

Notifications Integration:

HiveMind also enables your OVOS devices to function as notification targets within Home Assistant. This means you can configure Home Assistant automations to send spoken notifications directly to your OVOS devices, allowing them to "speak" alerts, reminders, or any other information you configure. This is exposed as a "Speak" notifier entity in Home Assistant.

!HiveMind notify service in Home Assistant

Media Player and Music Assistant Integration:

A fantastic feature of HiveMind integration is that your OVOS devices will show up as standard media players within Home Assistant. This allows you to control media playback on your OVOS devices directly from Home Assistant's media player interface. Furthermore, this integration extends to services like Music Assistant, enabling you to stream music and other audio content from Music Assistant through your OVOS devices, making them a seamless part of your whole-home audio system.

!HiveMind player in Home Assistant

!HiveMind player in Music Assistant

Give OVOS the Keys to the Kingdom

Finally, with the fantastic Skill HomeAssistant from community member mikejgray, you can give OVOS direct control over Home Assistant.

Install this skill, and your OVOS device can now command your smart home. Just say, "Hey Mycroft, turn on the living room lights," and watch the magic happen. It‚Äôs the classic voice assistant experience, but fully private, customizable, and powered by two best-in-class open-source projects.

The Perfect Match

When you let OVOS do the talking and Home Assistant do the automating, you get the best of both worlds. It‚Äôs a flexible, powerful, and fun combination that lets you build a smart home that is truly your own.

A Note on This Early Preview Release:

We're incredibly excited to share this integration with you! Please keep in mind that this is an early preview release and is still under active development. While it's functional and powerful, it hasn't undergone extensive testing and may have rough edges. We're actively working to refine it, and your feedback is invaluable! 

If you encounter any pain points or have ideas for improvements, please consider opening an issue or, even better, a Pull Request on our GitHub repositories. Your contributions help us make this even better for everyone. Thanks for being an early adopter and helping us shape the future of open-source voice!

Help Us Build Voice for Everyone

OpenVoiceOS is more than software, it‚Äôs a mission. If you believe voice assistants should be open, inclusive, and user-controlled, here‚Äôs how you can help:
üí∏ Donate: Help us fund development, infrastructure, and legal protection.
üì£ Contribute Open Data: Share voice samples and transcriptions under open licenses.
üåç Translate: Help make OVOS accessible in every language.

We're not building this for profit. We're building it for people. With your support, we can keep voice tech transparent, private, and community-owned.

üëâ Support the project here

---
Read more: <a href="https://tigregotico.github.io/blog/2025-09-17-ovos_ha_dream_team">View full article</a>
]]></content:encoded>
    </item>

    <item>
      <title>Making Synthetic Voices From Scratch</title>
      <link>https://tigregotico.github.io/blog/2025-06-26-making-synthetic-voices-from-scratch</link>
      <guid isPermaLink="true">https://tigregotico.github.io/blog/2025-06-26-making-synthetic-voices-from-scratch</guid>
      <pubDate>Thu, 26 Jun 2025 00:00:00 GMT</pubDate>
      <author>Unknown</author>
      <description>Creating a voice for a text-to-speech system usually requires a real person to spend hours recording audio. That‚Äôs expensive, time-consuming, and in many languages or accents, the voices just don‚Äôt exist at all</description>
      <content:encoded><![CDATA[
Making Synthetic Voices From Scratch

What‚Äôs the problem?

Creating a voice for a text-to-speech (TTS) system usually requires a real person to spend hours recording audio. That‚Äôs expensive, time-consuming, and in many languages or accents, the voices just don‚Äôt exist at all, especially for open-source or offline use.

What did we do?

We developed a technique that allows us to create synthetic voices completely from scratch, even if we don‚Äôt have recordings from a real person. These voices:

 Work offline, even on small devices like a Raspberry Pi,
 Can speak any language, if there‚Äôs a good donor system available,
 Are fully customizable in sound and tone.

How does it work?
Start with an existing voice - We use an existing TTS voice (from any source) to generate lots of fake speech and text pairs.
Transform it into a new voice - We apply a special voice conversion process to change the sound of the voice to something new, like a different gender, age, or accent.
Train a compact model - With this synthetic data, we train a new voice model that sounds natural, speaks fluently, and runs entirely offline.

Why is this special?

 We can create a new voice without needing anyone to record lines.
 The voices don‚Äôt rely on cloud services, they work 100% offline.
 Each voice can be customized to sound unique or to match a character, personality, or accent.

What about ethics?

We take voice rights seriously.

 If we‚Äôre using a real person‚Äôs voice, we always get clear permission.
 If no permission is available, we use public domain recordings or create original voices that don‚Äôt copy anyone.
Our process actually makes the voice less recognizable, which helps protect privacy and avoid impersonation risks.

Real-world example

We applied this method to European Portuguese, a language that had no good offline voice options. In a short time, we built 4 brand-new, high-quality voices, no recordings needed, and they all run on small local devices.

> üí° Did we mention OpenVoiceOS now has a huggingface account? find all our TTS voices and more at huggingface.co/OpenVoiceOS

In short:

> We‚Äôve found a way to build natural-sounding, offline-ready synthetic voices, without needing a real speaker. It‚Äôs fast, ethical, and opens the door for more voices in more languages, for everyone.

Help Us Build Voice for Everyone 

If you believe that voice assistants should be open, inclusive, and user-controlled, we invite you to support OVOS: 
üí∏ Donate: Your contributions help us pay for infrastructure, development, and legal protections. 
üì£ Contribute Open Data: Speech models need diverse, high-quality data. If you can share voice samples, transcripts, or datasets under open licenses, let's collaborate. 
üåç Help Translate: OVOS is global by nature. Translators make our platform accessible to more communities every day. 

We're not building this for profit. We're building it for people. And with your help, we can ensure open voice has a future‚Äîtransparent, private, and community-owned. 

üëâ Support the project here

---
Read more: <a href="https://tigregotico.github.io/blog/2025-06-26-making-synthetic-voices-from-scratch">View full article</a>
]]></content:encoded>
    </item>
  </channel>
</rss>